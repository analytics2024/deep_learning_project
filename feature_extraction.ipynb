{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39e0c68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323077bb18e2429aa4b53a558741f001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Enter the model for feature extraction: ', style=TextStyle(description_width='initâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/b0mdn8zd7msdn25jg6z_ln3c0000gn/T/ipykernel_7994/3577263131.py:17: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  text_input.on_submit(handle_submit)\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "text_input = widgets.Text()\n",
    "text_input.style.description_width = 'initial'  # Set description width to initial, allowing longer descriptions\n",
    "text_input.description = 'Enter the model for feature extraction: '\n",
    "\n",
    "# Display the widget\n",
    "display(text_input)\n",
    "\n",
    "feature_model = None\n",
    "\n",
    "# Define a function to handle the input\n",
    "def handle_submit(sender):\n",
    "    global feature_model\n",
    "    feature_model = text_input.value\n",
    "\n",
    "# Set the function to handle input submission\n",
    "text_input.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deeb3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from pickle import dump\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.applications import ResNet50, VGG16\n",
    "\n",
    "def create_custom_cnn_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        # Convolutional layers...\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        # Output layer with 4096 units\n",
    "        keras.layers.Dense(4096)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def feature_extractions_cnn(directory):\n",
    "    \"\"\"\n",
    "    Input: directory of images\n",
    "    Return: A dictionary of features extracted by the custom CNN model.\n",
    "    \"\"\"\n",
    "    input_shape = (224, 224, 3)  # Assuming input images are resized to 224x224\n",
    "    num_classes = 4096  # Output feature size\n",
    "    \n",
    "    # Create and compile the custom CNN model\n",
    "    input_shape = (224, 224, 3)\n",
    "    model = create_custom_cnn_model(input_shape)\n",
    "    model = keras.models.Model(inputs=model.input, outputs=model.layers[-1].output) \n",
    "# custom_cnn_model = create_custom_cnn_model(input_shape)\n",
    "    model.compile(optimizer='adam', loss='mse')  # Adjust loss and optimizer as needed\n",
    "    features = {}\n",
    "    for f in os.listdir(directory):\n",
    "        filename = os.path.join(directory, f)\n",
    "        identifier = f.split('.')[0]\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = keras.preprocessing.image.load_img(filename, target_size=(input_shape[0], input_shape[1]))\n",
    "        arr = keras.preprocessing.image.img_to_array(image)\n",
    "        arr = np.expand_dims(arr, axis=0)\n",
    "        arr = arr / 255.0  # Normalize pixel values\n",
    "        \n",
    "        # Extract feature\n",
    "        feature = model.predict(arr)\n",
    "        features[identifier] = feature\n",
    "        \n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "#Resnet 50 Model\n",
    "\n",
    "\n",
    "def feature_extractions_resnet(directory):\n",
    "    \"\"\"\n",
    "    Input: directory of images\n",
    "    Return: A dictionary of features extracted by VGG-16, size 4096.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load ResNet50 model pre-trained on ImageNet data\n",
    "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # Add a Dense layer with 4096 units\n",
    "    x = base_model.output\n",
    "    x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "\n",
    "    # Create a new model with the modified top\n",
    "    model = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    features = {}\n",
    "    for f in os.listdir(directory):\n",
    "        filename = directory + \"/\" + f\n",
    "        identifier = f.split('.')[0]\n",
    "        \n",
    "        image = keras.preprocessing.image.load_img(filename, target_size=(224,224))\n",
    "        arr = keras.preprocessing.image.img_to_array(image, dtype=np.float32)\n",
    "        arr = arr.reshape((1, arr.shape[0], arr.shape[1], arr.shape[2]))\n",
    "        arr = keras.applications.resnet50.preprocess_input(arr)\n",
    "    \n",
    "        feature = model.predict(arr, verbose=0)\n",
    "        features[identifier] = feature\n",
    "    return features \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#VGG 50 Model\n",
    "def feature_extractions_vgg16(directory):\n",
    "    \"\"\"\n",
    "    Input: directory of images\n",
    "    Return: A dictionary of features extracted by VGG-16, size 4096.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load ResNet50 model pre-trained on ImageNet data\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # Add a Dense layer with 4096 units\n",
    "    x = base_model.output\n",
    "    x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "\n",
    "    # Create a new model with the modified top\n",
    "    model = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    features = {}\n",
    "    for f in os.listdir(directory):\n",
    "        filename = directory + \"/\" + f\n",
    "        identifier = f.split('.')[0]\n",
    "        \n",
    "        image = keras.preprocessing.image.load_img(filename, target_size=(224,224))\n",
    "        arr = keras.preprocessing.image.img_to_array(image, dtype=np.float32)\n",
    "        arr = arr.reshape((1, arr.shape[0], arr.shape[1], arr.shape[2]))\n",
    "        arr = keras.applications.vgg16.preprocess_input(arr)\n",
    "    \n",
    "        feature = model.predict(arr, verbose=0)\n",
    "        features[identifier] = feature\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_model.lower() == \"custom\":\n",
    "    print(\"Ruuning the custom feature file\")\n",
    "    cnn_features = feature_extractions_cnn(\"Flicker8k_Dataset\")\n",
    "    with open(\"cnn_features.pkl\", \"wb\") as file:\n",
    "        pickle.dump(cnn_features, file)\n",
    "        \n",
    "if feature_model.lower() == 'resnet50':\n",
    "    print(\"Ruuning the resnet feature file\")\n",
    "    resnet_features = feature_extractions_resnet(\"Flicker8k_Dataset\")\n",
    "    with open(\"resnet_features.pkl\", \"wb\") as file:\n",
    "        pickle.dump(resnet_features, file)\n",
    "        \n",
    "else:\n",
    "    print(\"Ruuning the vgg16 feature file\")\n",
    "    vgg16_features = feature_extractions_vgg16(\"Flicker8k_Dataset\")\n",
    "    with open(\"vgg16_features.pkl\", \"wb\") as file:\n",
    "        pickle.dump(vgg16_features, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cc3257a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing of the code\n",
    "len(vgg16_features['1000268201_693b08cb0e'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
